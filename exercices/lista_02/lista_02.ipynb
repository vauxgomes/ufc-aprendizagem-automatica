{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb40aa9",
   "metadata": {},
   "source": [
    "# Lista 2 - Regressão Logística e Classificadores Estatísticos\n",
    "\n",
    "## Sumário\n",
    "\n",
    "- Questão 1: [A](#Questão-1-a.), [B](#Questão-1-b.)\n",
    "- Questão 2: [A](#Questão-2-a.), [B](#Questão-2-b.)\n",
    "\n",
    "<span style=\"position: absolute; top: 10px; right: 10px; background: green; padding: 0.5em; color: white; border-radius: 8px; font-weight: bold\">Vaux Gomes</span>\n",
    "\n",
    "## Implementações\n",
    "\n",
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3dd608a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.base import \\\n",
    "    BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e31081",
   "metadata": {},
   "source": [
    "### Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5773f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, perc=0.66):\n",
    "    ''' Splits the data into two peaces '''\n",
    "    idx = int(perc * data.shape[0])\n",
    "    return data[:idx], data[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be431a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(clf, X, y, folds=10, stats=False, progress=False):\n",
    "    ''' Runs a full n-fold cross-validation on clf '''\n",
    "    \n",
    "    # Auxiliary\n",
    "    accuracy = {'global': [], 'class': []}\n",
    "    p_size = X.shape[0]/folds # partition size (float)\n",
    "    \n",
    "    # Normalizer\n",
    "    normalizer = MinMax()\n",
    "\n",
    "    # Cross validation\n",
    "    for n in range(folds):\n",
    "        # Partition boundaries\n",
    "        start, end = int(n * p_size), int((n + 1) * p_size)\n",
    "\n",
    "        # Normalized Train\n",
    "        X_train = normalizer.fit_transform(np.concatenate([X[:start], X[end:]]))\n",
    "        y_train = np.concatenate([y[:start], y[end:]])\n",
    "\n",
    "        # Normalized Validation\n",
    "        X_valid = normalizer.fit_transform(X[start:end])\n",
    "        y_valid = y[start:end]\n",
    "\n",
    "        # Training\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Prediction\n",
    "        y_hat = clf.predict(X_valid)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        c_matrix = confusion_matrix(y_valid, y_hat)\n",
    "\n",
    "        # Accuracy\n",
    "        acc = c_matrix.diagonal().sum()/c_matrix.sum()       # General\n",
    "        accuracy['global'].append(acc)\n",
    "\n",
    "        acc_class = c_matrix.diagonal()/c_matrix.sum(axis=1) # By class\n",
    "        accuracy['class'].append(acc_class)\n",
    "        \n",
    "        # Progress printing for watching the magic happening\n",
    "        if progress:\n",
    "            print(end='-')   \n",
    "        \n",
    "    # Printing\n",
    "    if stats:\n",
    "        print('-'*(50 - (n if progress else 0)))\n",
    "        print(f' {clf}')\n",
    "        print('-'*50)\n",
    "        print(' Global Accuracy')\n",
    "        print(f'  - Mean:               {np.mean(accuracy[\"global\"])}')\n",
    "        print(f'  - Standard deviation: {np.std(accuracy[\"global\"])}')\n",
    "        print(' Accuracy by class')\n",
    "        print(f'  - Mean:               {np.mean(accuracy[\"class\"], axis=0)}')\n",
    "        print(f'  - Standard deviation: {np.std(accuracy[\"class\"], axis=0)}')\n",
    "        \n",
    "    # Return\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ed02f",
   "metadata": {},
   "source": [
    "### MinMax Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85043ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMax():\n",
    "    ''' MinMax Normalizer '''\n",
    "\n",
    "    #\n",
    "    def fit_transform(self, X):\n",
    "        self.min = X.min(axis=0)\n",
    "        self.max = X.max(axis=0)\n",
    "        \n",
    "        return (X - self.min)/(self.max - self.min)\n",
    "    \n",
    "    #\n",
    "    def transform(self, X):\n",
    "        return (X - self.min)/(self.max - self.min)\n",
    "    \n",
    "    #\n",
    "    def restore(self, X):\n",
    "        return X*(self.max - self.min) + self.min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b0e28",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression via Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a82b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionGD(BaseEstimator, RegressorMixin):\n",
    "    ''' Binary Logistic Regression via Gradient Descent (GD) '''\n",
    "\n",
    "    #\n",
    "    def __init__(self, alpha=10**-3, epocs=300):\n",
    "        self.epocs = epocs\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # \n",
    "    def fit(self, X, y):\n",
    "        # Parameters\n",
    "        self.bias = 0                       # Bias\n",
    "        self.weights = np.zeros(X.shape[1]) # Weights\n",
    "        \n",
    "        # Main loop\n",
    "        for i in range(self.epocs):\n",
    "            # Prediction\n",
    "            y_hat = self.activation(np.matmul(self.weights, X.T) + self.bias)\n",
    "            \n",
    "            # Error\n",
    "            err = y_hat - y\n",
    "            \n",
    "            # Gradients\n",
    "            g_bias = err.mean()\n",
    "            g_weights = X.T.dot(err).mean(axis=1)\n",
    "            \n",
    "            # Update: using 'minus' due error calculation (ŷ - y)\n",
    "            self.bias -= self.alpha * g_bias\n",
    "            self.weights -= self.alpha * g_weights\n",
    "         \n",
    "    #\n",
    "    def predict(self, X, R_cost=1):\n",
    "        ''' R_cost: Decision Limiar '''\n",
    "        \n",
    "        y_hat = np.matmul(X, self.weights.T) + self.bias  \n",
    "        return np.where(self.activation(y_hat) > (1/(R_cost+1)), 1, 0)\n",
    "\n",
    "    #\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        ''' Sigmoid function '''\n",
    "        return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f58a95",
   "metadata": {},
   "source": [
    "### Softmax Regression via Gradient Descent - Multivariate\n",
    "\n",
    "> Calculei os pesos por classe, mas entendo que tem uma maneira de fazer o cálculo usando o numpy. Só não tive tempo. : ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad857e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegressionGD(BaseEstimator, RegressorMixin):\n",
    "    ''' Softmax Regression via Gradient Descent - Multivariate '''\n",
    "\n",
    "    #\n",
    "    def __init__(self, alpha=10**-3, epocs=300):\n",
    "        self.epocs = epocs\n",
    "        self.alpha = alpha\n",
    "\n",
    "    #\n",
    "    def fit(self, X, y):\n",
    "        # Aux\n",
    "        self.classes, self.counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Parameters\n",
    "        self.bias = np.zeros(self.classes.shape[0])                  # Bias\n",
    "        self.weights = np.zeros((self.classes.shape[0], X.shape[1])) # Weights\n",
    "        \n",
    "        # Binarization of y\n",
    "        binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "        binarizer.fit(range(self.classes.size))\n",
    "        #\n",
    "        y_ = binarizer.transform(y)\n",
    "        \n",
    "        # Main loop\n",
    "        for i in range(self.epocs):\n",
    "            #\n",
    "            parts = self.activation(X)\n",
    "            \n",
    "            #\n",
    "            for k, c in enumerate(self.classes):\n",
    "                # Prediction\n",
    "                y_hat = parts[k]/parts.sum(axis=0)\n",
    "\n",
    "                # Error of class k\n",
    "                err_k = y_hat - y_[:, k:k+1]\n",
    "\n",
    "                # Gradients\n",
    "                g_bias = err_k.mean()\n",
    "                g_weights = X.T.dot(err_k).mean(axis=1)\n",
    "                \n",
    "                # Update: using 'minus' due error calculation (ŷ - y)\n",
    "                self.bias[k] -= self.alpha * g_bias\n",
    "                self.weights[k] -= self.alpha * g_weights\n",
    "                \n",
    "    #\n",
    "    def predict(self, X):\n",
    "        #\n",
    "        y_hat = np.matmul(X, self.weights.T) + self.bias  \n",
    "        return np.argmax(y_hat, axis=1)\n",
    "\n",
    "    #\n",
    "    def activation(self, X):\n",
    "        ''' Softmax '''\n",
    "        #\n",
    "        parts = []\n",
    "        for i, c in enumerate(self.classes):\n",
    "            parts.append(np.exp(self.weights[i].T * X + self.bias[i]))\n",
    "\n",
    "        #\n",
    "        return np.array(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f47e8f",
   "metadata": {},
   "source": [
    "### Análise do discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b3e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminantAnalysis(BaseEstimator, RegressorMixin):\n",
    "    ''' Gaussian Discriminant Analysis - Multivariate '''\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Classes and Counts\n",
    "        self.classes, self.counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Distributions (Prior)\n",
    "        self.probs = self.counts / X.shape[0]\n",
    "        \n",
    "        # Stats for class\n",
    "        mean  = []\n",
    "        cov   = []\n",
    "        inv   = []\n",
    "        det   = []\n",
    "        \n",
    "        #\n",
    "        for c in self.classes:\n",
    "            #\n",
    "            subset = X[y.reshape(y.shape[0]) == c]\n",
    "            \n",
    "            #\n",
    "            mean.append(subset.mean(axis=0))\n",
    "            \n",
    "            #\n",
    "            cov_ = np.cov(subset.T)\n",
    "            \n",
    "            cov.append(cov_)                 # n x n\n",
    "            inv.append(np.linalg.inv(cov_))  # n x n\n",
    "            det.append(np.linalg.det(cov_))  # scalar\n",
    "            \n",
    "        # Converting arrays\n",
    "        self.mean = np.array(mean)\n",
    "        self.cov = np.array(cov)\n",
    "        self.inv = np.array(inv)\n",
    "        self.det = np.array(det)\n",
    "        \n",
    "    #\n",
    "    def predict(self, X):\n",
    "        y_hats = []\n",
    "        part = []\n",
    "        \n",
    "        # For each class\n",
    "        for i, c in enumerate(self.classes):\n",
    "            part.append((np.sqrt((2 * np.pi)**X.shape[1] * self.det[i]))**-1)\n",
    "            \n",
    "        for x in X:\n",
    "            preds = []\n",
    "            \n",
    "            for i, c in enumerate(self.classes):\n",
    "                preds.append(part[i] * np.exp((x - clf.mean[i]).T.dot(clf.inv[i]).dot(x - clf.mean[i])*-0.5))\n",
    "                \n",
    "            y_hats.append(np.argmax(preds))\n",
    "            \n",
    "        return y_hats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258548d",
   "metadata": {},
   "source": [
    "### Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d55088fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(BaseEstimator, RegressorMixin):\n",
    "    ''' Gaussian Naive Bayes '''\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Classes and Counts\n",
    "        self.classes, self.counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Distributions (Prior)\n",
    "        self.probs = self.counts / X.shape[0]\n",
    "        \n",
    "        # Stats for class\n",
    "        mean = []\n",
    "        var = []\n",
    "        \n",
    "        #\n",
    "        for c in self.classes:\n",
    "            #\n",
    "            subset = X[y.reshape(y.shape[0]) == c]\n",
    "            \n",
    "            #\n",
    "            mean.append(subset.mean(axis=0))\n",
    "            var.append(subset.var(axis=0))\n",
    "         \n",
    "        # Converting arrays\n",
    "        self.mean = np.array(mean)\n",
    "        self.var = np.array(var)\n",
    "            \n",
    "    #\n",
    "    def predict(self, X):\n",
    "        # Posterior for each class\n",
    "        y_hats = []\n",
    "        \n",
    "        #\n",
    "        for i, c in enumerate(self.classes):\n",
    "            prior = np.log(self.probs[i])\n",
    "            \n",
    "            c1 = np.log(2 * np.pi * self.var[i]).sum()/2\n",
    "            c2 = ((((X - self.mean[i])**2)/self.var[i])).sum(axis=1)/2\n",
    "            \n",
    "            y_hats.append(prior - c1 - c2)\n",
    "\n",
    "        #\n",
    "        return np.argmax(np.array(y_hats), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d98c7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Considere o conjunto de dados disponível em `breastcancer.csv`, organizado em 31 colunas, sendo as 30 primeiras colunas os atributos e a última coluna a saída. Os 30 atributos coletados de exames médicos são usados no diagnóstico do câncer de mama, sendo `1` a classe positiva e `0` a classe negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45c9ec",
   "metadata": {},
   "source": [
    "#### Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac1c6ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCW: (569, 31)\n",
      "Vehicle: (846, 19)\n"
     ]
    }
   ],
   "source": [
    "# Importação dos conjuntos de dados\n",
    "bcw = np.genfromtxt('breastcancer.csv', delimiter=',')\n",
    "vehicle = np.genfromtxt('vehicle.csv', delimiter=',')\n",
    "\n",
    "print(f'BCW: {bcw.shape}')\n",
    "print(f'Vehicle: {vehicle.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118ed51",
   "metadata": {},
   "source": [
    "### Questão 1 a.\n",
    "\n",
    "Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    " - Regressão logística (treinado com GD ou SGD);\n",
    " - Análise do discriminante Gaussiano ;\n",
    " - Naive Bayes Gaussiano ;\n",
    " \n",
    "### Questão 1 b.\n",
    "\n",
    "Para cada modelo criado, reporte valor médio e desvio padrão da acurácia global e da acurácia por classe\n",
    " \n",
    "[Início ↑](#Sumário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02cb82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bcw = bcw[:, :-1]\n",
    "y_bcw = bcw[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bda73",
   "metadata": {},
   "source": [
    "#### Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04fa0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " BinaryLogisticRegressionGD()\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.8120614035087719\n",
      "  - Standard deviation: 0.07087134388319727\n",
      " Accuracy by class\n",
      "  - Mean:               [0.75147913 0.90409341]\n",
      "  - Standard deviation: [0.10383044 0.06414726]\n"
     ]
    }
   ],
   "source": [
    "clf = BinaryLogisticRegressionGD(epocs=300)\n",
    "_ = cross_val(clf, X_bcw, y_bcw, stats=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294e6ac",
   "metadata": {},
   "source": [
    "#### Análise do discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a88c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " GaussianDiscriminantAnalysis()\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.611748120300752\n",
      "  - Standard deviation: 0.1150275986902135\n",
      " Accuracy by class\n",
      "  - Mean:               [0.44744712 0.80878053]\n",
      "  - Standard deviation: [0.23118794 0.13944683]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianDiscriminantAnalysis()\n",
    "_ = cross_val(clf, X_bcw, y_bcw, stats=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147052f",
   "metadata": {},
   "source": [
    "#### Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5f9cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " GaussianNaiveBayes()\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.7963972431077694\n",
      "  - Standard deviation: 0.1007025420741757\n",
      " Accuracy by class\n",
      "  - Mean:               [0.7112618  0.98365079]\n",
      "  - Standard deviation: [0.14070952 0.02583013]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNaiveBayes()\n",
    "_ = cross_val(clf, X_bcw, y_bcw, stats=True, folds=10, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465c5b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questão 2\n",
    "\n",
    "Considere o conjunto de dados disponível em vehicle.csv , organizado em 19 colunas, sendo as 18 primeiras colunas os atributos e a última coluna a saída. Os 18 atributos caracterizam a silhueta de veículos, extraídos pelo método HIPS (Hierarchical Image Processing System). A tarefa consiste em classificar o veículo em 4 classes (bus, pel, saab, e van).\n",
    "\n",
    "> Os dados já foram carregados\n",
    "\n",
    "### Questão 2 a.\n",
    "\n",
    "Considerando uma validação cruzada em 10 folds, avalie modelos de classi\u001c",
    "\n",
    "\n",
    "cação multiclasse nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "\n",
    " - Regressão softmax (treinado com GD ou SGD);\n",
    " - Análise do discriminante Gaussiano;\n",
    " - Naive Bayes Gaussiano;\n",
    "\n",
    "### Questão 2 b.\n",
    "\n",
    "Para cada modelo criado, reporte valor médio e desvio padrão da acurácia global e da acurácia por classe\n",
    "\n",
    "[Início ↑](#Sumário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb3ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vehicle = vehicle[:, :-1]\n",
    "y_vehicle = vehicle[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933fd76b",
   "metadata": {},
   "source": [
    "#### Regressão softmax (treinado com GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8048d8d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " SoftmaxRegressionGD(epocs=500)\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.469313725490196\n",
      "  - Standard deviation: 0.06377199798879717\n",
      " Accuracy by class\n",
      "  - Mean:               [0.41929187 0.44579836 0.51681797 0.51623721]\n",
      "  - Standard deviation: [0.08168527 0.09286956 0.11028727 0.13179864]\n"
     ]
    }
   ],
   "source": [
    "clf = SoftmaxRegressionGD(epocs=500)\n",
    "_ = cross_val(clf, X_vehicle, y_vehicle, stats=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9525c",
   "metadata": {},
   "source": [
    "#### Análise do discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b045e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " GaussianDiscriminantAnalysis()\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.5185294117647058\n",
      "  - Standard deviation: 0.16947474405240176\n",
      " Accuracy by class\n",
      "  - Mean:               [0.75306784 0.49360076 0.14528295 0.76269339]\n",
      "  - Standard deviation: [0.19192543 0.40388856 0.2104879  0.26159325]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianDiscriminantAnalysis()\n",
    "_ = cross_val(clf, X_vehicle, y_vehicle, stats=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b61b36",
   "metadata": {},
   "source": [
    "#### Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7235e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " GaussianNaiveBayes()\n",
      "--------------------------------------------------\n",
      " Global Accuracy\n",
      "  - Mean:               0.42411764705882354\n",
      "  - Standard deviation: 0.10234967545028588\n",
      " Accuracy by class\n",
      "  - Mean:               [0.42163063 0.20453796 0.20654014 0.92622222]\n",
      "  - Standard deviation: [0.10138334 0.16913912 0.18626918 0.09311741]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNaiveBayes()\n",
    "_ = cross_val(clf, X_vehicle, y_vehicle, stats=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
